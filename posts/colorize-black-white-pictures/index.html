<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=X-UA-Compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>How to colorize black & white pictures. | Mind the gap blog: Insights, ideas, and inspiration for the tech-savvy and curious.</title>
<meta name=keywords content="containers,ai,openvino,docker,ubuntu"><meta name=description content="If you’re looking to bring a stack of old family photos back to life, check out Ubuntu’s demo on how to use OpenVINO on Ubuntu containers to colorize monochrome pictures. This magical use of containers, neural networks, and Kubernetes is packed with helpful resources and a fun way to dive into deep learning!
A version of Part 1 and Part 2 of this article was first published on Ubuntu’s blog."><meta name=author content="Valentin Viennot"><link rel=canonical href=https://mindthegapblog.com/posts/colorize-black-white-pictures/><meta name=google-site-verification content="G-RTFFSGBVBC"><link crossorigin=anonymous href=/assets/css/stylesheet.b183800e2cfbb62c3bce2b2ba56cdb2dd33af76c75cf4550173d5dfebd7c68a6.css integrity="sha256-sYOADiz7tiw7zisrpWzbLdM692x1z0VQFz1d/r18aKY=" rel="preload stylesheet" as=style><link rel=icon href=https://mindthegapblog.com/favicon.png><link rel=icon type=image/png sizes=16x16 href=https://mindthegapblog.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://mindthegapblog.com/favicon-32x32.png><link rel=apple-touch-icon href=https://mindthegapblog.com/favicon.png><link rel=mask-icon href=https://mindthegapblog.com/favicon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><script async src="https://www.googletagmanager.com/gtag/js?id=G-RTFFSGBVBC"></script><script>var doNotTrack=!1;if(!doNotTrack){window.dataLayer=window.dataLayer||[];function gtag(){dataLayer.push(arguments)}gtag("js",new Date),gtag("config","G-RTFFSGBVBC",{anonymize_ip:!1})}</script><meta property="og:title" content="How to colorize black & white pictures."><meta property="og:description" content="If you’re looking to bring a stack of old family photos back to life, check out Ubuntu’s demo on how to use OpenVINO on Ubuntu containers to colorize monochrome pictures. This magical use of containers, neural networks, and Kubernetes is packed with helpful resources and a fun way to dive into deep learning!
A version of Part 1 and Part 2 of this article was first published on Ubuntu’s blog."><meta property="og:type" content="article"><meta property="og:url" content="https://mindthegapblog.com/posts/colorize-black-white-pictures/"><meta property="og:image" content="https://mindthegapblog.com/mindthegap-tmp-picture.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2023-01-17T11:00:29+02:00"><meta property="article:modified_time" content="2023-01-17T11:00:29+02:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://mindthegapblog.com/mindthegap-tmp-picture.png"><meta name=twitter:title content="How to colorize black & white pictures."><meta name=twitter:description content="If you’re looking to bring a stack of old family photos back to life, check out Ubuntu’s demo on how to use OpenVINO on Ubuntu containers to colorize monochrome pictures. This magical use of containers, neural networks, and Kubernetes is packed with helpful resources and a fun way to dive into deep learning!
A version of Part 1 and Part 2 of this article was first published on Ubuntu’s blog."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://mindthegapblog.com/posts/"},{"@type":"ListItem","position":2,"name":"How to colorize black \u0026 white pictures.","item":"https://mindthegapblog.com/posts/colorize-black-white-pictures/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"How to colorize black \u0026 white pictures.","name":"How to colorize black \u0026 white pictures.","description":"If you’re looking to bring a stack of old family photos back to life, check out Ubuntu’s demo on how to use OpenVINO on Ubuntu containers to colorize monochrome pictures. This magical use of containers, neural networks, and Kubernetes is packed with helpful resources and a fun way to dive into deep learning!\nA version of Part 1 and Part 2 of this article was first published on Ubuntu’s blog.","keywords":["containers","ai","openvino","docker","ubuntu"],"articleBody":"If you’re looking to bring a stack of old family photos back to life, check out Ubuntu’s demo on how to use OpenVINO on Ubuntu containers to colorize monochrome pictures. This magical use of containers, neural networks, and Kubernetes is packed with helpful resources and a fun way to dive into deep learning!\nA version of Part 1 and Part 2 of this article was first published on Ubuntu’s blog.\nA few words about OpenVINO on Ubuntu containers Docker image security isn’t only about provenance and supply chains; it’s also about the user experience. More specifically, the developer experience.\nAs the most popular container image in its category, the Ubuntu base image provides a seamless, easy-to-set-up experience. From public cloud hosts to IoT devices, the Ubuntu experience is consistent and loved by developers. In this blog, you’ll see that using Ubuntu Docker images greatly simplifies component containerization. We even used a prebuilt \u0026 preconfigured container image for NGINX.\nWhen you’re ready to deploy deep learning inference in production, binary size and memory footprint are key considerations – especially when deploying at the edge. OpenVINO provides a lightweight Inference Engine with a binary size of just over 40MB for CPU-based inference. It also provides a Model Server for serving models at scale and managing deployments.\nOpenVINO includes open-source developer tools to improve model inference performance. The first step is to convert a deep learning model (trained with TensorFlow, PyTorch,…) to an Intermediate Representation (IR) using the Model Optimizer. In fact, it cuts the model’s memory usage in half by converting it from FP32 to FP16 precision.\nOpen Model Zoo provides pre-trained models that work for real-world use cases to get you started quickly. Additionally, Python and C++ sample codes demonstrate how to interact with the model. More than 280 pre-trained models are available to download, from speech recognition to natural language processing and computer vision.\nFor this blog, we will use the pre-trained colorization models from Open Model Zoo and serve them with Model Server.\nDemo architecture “As a user, I can drag and drop my old black and white pictures to my browser so that it displays their ready-to-download colorized version.” – said the PM (me).\nFor that – replied the one-time software engineer (still me) – we only need:\nA fancy yet lightweight frontend component. OpenVINO™ Model Server to serve the neural network colorization predictions. A very light backend component. Whilst we could target the Model Server directly with the frontend (it exposes a REST API), we need to apply transformations to the submitted image. The colorization models, in fact, each expect a specific input.\nFinally, we’ll deploy these three services with Kubernetes because … well … because it’s groovy. And if you think otherwise (everyone is allowed to have a flaw or two), you’ll find a fully functional docker-compose.yaml in the source code repository.\nIn the upcoming sections, we will first look at each component and then show how to deploy them with Kubernetes using MicroK8s. Don’t worry; the full source code is freely available, and I’ll link you to the relevant parts.\ngRPC vs REST APIs The OpenVINO Model Server provides inference as a service endpoints for serving models in OpenVINO IR or ONNX format. It also offers centralized model management to serve multiple different models or different versions of the same model and model pipelines.\nThe server offers two sets of APIs to interface with it: REST and gRPC. Both APIs are compatible with TensorFlow Serving and expose endpoints for prediction, checking model metadata, and monitoring model status. For use cases where low latency and high throughput are needed, you’ll probably want to interact with the model server via the gRPC API. Indeed, it introduces a significantly smaller overhead than REST. (Read more about gRPC.)\nOpenVINO Model Server is distributed as a Docker image with minimal dependencies. For this demo, we will use the Model Server container image deployed to a MicroK8s cluster. This combination of lightweight technologies is suitable for small deployments such as a developer laptop or edge computing devices.\nNeural network – OpenVINO Model Server The colorization neural network is published under the BSD 2-clause License, accessible from the Open Model Zoo. It’s pre-trained, so we don’t need to understand it in order to use it. However, let’s look closer to understand what input it expects. I also strongly encourage you to read the original work from Richard Zhang, Phillip Isola, and Alexei A. Efros. They made the approach super accessible and understandable on this website and in the original paper.\nAs you can see on the network architecture diagram, the neural network uses an unusual color space: LAB. In fact, there are many 3-dimensional spaces to code colors: RGB, HSL, HSV, etc. The LAB format is relevant here as it fully isolates the color information from the lightness information. Therefore, a grayscale image can be coded with only the L (for Lightness) axis. We will thereore only send the L axis to the neural network’s input. It will generate predictions for the colors coded on the two remaining axes: A and B.\nFrom the architecture diagram, we can also see that the model expects a 256×256 pixels input size. For these reasons, we cannot just send our RGB-coded grayscale picture in its original size to the network. We need to first transform it.\nWe compare the results of two different model versions for the demo. Let them be called ‘V1’ (Siggraph) and ‘V2’. The models are served with the same instance of the OpenVINO™ Model Server as two different models. (We could also have done it with two different versions of the same model – read more in the documentation.)\nFinally, to build the Docker image, we use the first stage from the Ubuntu-based development kit to download and convert the model. We then rebase on the more lightweight Model Server image.\n# Dockerfile: github.com/valentincanonical/colouriser-demo/blob/main/modelserver/Dockerfile FROM openvino/ubuntu20_dev:latest AS omz # download and convert the model … FROM openvino/model_server:latest # copy the model files and configure the Model Server … Backend – Ubuntu-based Flask app (Python) For the backend microservice that interfaces between the user-facing frontend and the Model Server hosting the neural network, we chose to use Python. There are many valuable libraries to manipulate data, including images, specifically for machine learning applications. To provide web serving capabilities, Flask is an easy choice.\nThe backend takes an HTTP POST request with the to-be-colorized picture. It synchronously returns the colorized result using the neural network predictions. In between – as we’ve just seen – it needs to convert the input to match the model architecture and to prepare the output to show a displayable result.\nHere’s what the transformation pipeline looks like on the input:\nAnd the output looks something like that:\nTo containerize our Python Flask application, we use the first stage with all the development dependencies to prepare our execution environment. We copy it onto a fresh Ubuntu base image to run it, configuring the model server’s gRPC connection.\nFrontend – Ubuntu-based NGINX container and Svelte app Finally, I put together a fancy UI for you to try the solution out. It’s an effortless single-page application with a file input field. It can display side-by-side the results from the two different colorization models.\nI used Svelte to build the demo as a dynamic frontend. Below each colorization result, there’s even a saturation slider (using a CSS transformation) so that you can emphasize the predicted colors and better compare the before and after.\nTo ship this frontend application, we again use a Docker image. We first build the application using the Node base image. We then rebase it on top of a preconfigured Ubuntu-based NGINX image. A reverse proxy on the frontend side serves as a passthrough to the backend on the /api endpoint to simplify the deployment configuration. We do that directly in an NGINX.conf configuration file copied to the NGINX templates directory. The container image is preconfigured to use these template files with environment variables.\nDeployment with Kubernetes I hope you had the time to digitalize some of your old black and white pictures because things are about to get serious(ly colorized).\nWe’ll assume you already have a running Kubernetes installation from the next section. If not, I encourage you to go through this MicroK8s tutorial.\nBuild the components’ Docker images Every component comes with a Dockerfile to build itself in a standard environment and ship its deployment dependencies (read What are containers for more information). They all create an Ubuntu-based Docker image for a consistent developer experience.\nBefore deploying our colorizer app with Kubernetes, we need to build and push the components’ images. They need to be hosted in a registry accessible from our Kubernetes cluster. We will use the built-in local registry with MicroK8s. Depending on your network bandwidth, building and pushing the images will take a few minutes or more.\ngit clone https://github.com/valentincanonical/colouriser-demo.git cd colouriser-demo # Backend docker build backend -t localhost:32000/backend:latest docker push localhost:32000/backend:latest # Model Server docker build modelserver -t localhost:32000/modelserver:latest docker push localhost:32000/modelserver:latest # Frontend docker build frontend -t localhost:32000/frontend:latest docker push localhost:32000/frontend:latest Apply the Kubernetes configuration files All the components are now ready for deployment. The Kubernetes configuration files are available as deployments and services YAML descriptors in the ./K8s folder of the demo repository. We can apply them all at once, in one command:\nkubectl apply -f ./k8s Give it a few minutes. You can watch the app being deployed with watch kubectl status. Of all the services, the frontend one has a specific NodePort configuration to make it publicly accessible by targeting the Node IP address.\nOnce ready, you can access the demo app at http://localhost:30000/ (or replace localhost with a cluster node IP address if you’re using a remote cluster). Pick an image from your computer, and get it colorized!\nThat’s a wrap! All in all, the project was pretty easy considering the task we accomplished. Thanks to Ubuntu containers, building each component’s image with multi-stage builds was a consistent and straightforward experience. And thanks to OpenVINO™ and the Open Model Zoo, serving a pre-trained model with excellent inference performance was a simple task accessible to all developers.\nCherry on top, you didn’t even have to share your pics over the Internet to get it done!\n","wordCount":"1716","inLanguage":"en","datePublished":"2023-01-17T11:00:29+02:00","dateModified":"2023-01-17T11:00:29+02:00","author":{"@type":"Person","name":"Valentin Viennot"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://mindthegapblog.com/posts/colorize-black-white-pictures/"},"publisher":{"@type":"Organization","name":"Mind the gap blog: Insights, ideas, and inspiration for the tech-savvy and curious.","logo":{"@type":"ImageObject","url":"https://mindthegapblog.com/favicon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://mindthegapblog.com/ accesskey=h title="m ind the ga p (Alt + H)">m ind the ga p</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://mindthegapblog.com/tags/ title=Tags><span>Tags</span></a></li><li><a href=https://valentin.viennot.me/ title=Portfolio><span>Portfolio</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>How to colorize black & white pictures.</h1><div class=post-meta>&lt;span title='2023-01-17 11:00:29 +0200 +0200'>January 17, 2023&lt;/span>&amp;nbsp;·&amp;nbsp;9 min&amp;nbsp;·&amp;nbsp;Valentin Viennot&nbsp;|&nbsp;<a href=https://github.com/valentinviennot/mindthegapblog/tree/main/content/posts/colorize-containers/index.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p><em>If you’re looking to bring a stack of old family photos back to life, check out Ubuntu’s demo on how to use OpenVINO on Ubuntu containers to colorize monochrome pictures. This magical use of containers, neural networks, and Kubernetes is packed with helpful resources and a fun way to dive into deep learning!</em></p><p><em>A version of</em> <a href=https://ubuntu.com/blog/how-to-colourise-black-white-pictures-openvino-containers-part-1><em>Part 1</em></a> <em>and</em> <a href=https://ubuntu.com/blog/how-to-colourise-black-white-pictures-openvino-containers-part-2><em>Part 2</em></a> <em>of this article was first published on Ubuntu’s blog.</em></p><p><img loading=lazy src=./colorize-example-cat-walking-through-grass.png alt="Colorize example cat walking through grass"></p><h2 id=a-few-words-about-openvino-on-ubuntu-containers>A few words about OpenVINO on Ubuntu containers<a hidden class=anchor aria-hidden=true href=#a-few-words-about-openvino-on-ubuntu-containers>#</a></h2><p>Docker image security isn’t only about <a href=https://ubuntu.com/blog/secure-containers-supply-chain-intel-openvino-canonical>provenance and supply chains;</a> it’s also about the user experience. More specifically, the developer experience.</p><p>As the most popular container image in its category, the Ubuntu <a href=https://gallery.ecr.aws/lts/ubuntu>base image</a> provides a seamless, easy-to-set-up experience. From public cloud hosts to IoT devices, the Ubuntu experience is consistent and loved by developers. In this blog, you’ll see that using Ubuntu Docker images greatly simplifies component containerization. We even used a <a href=https://hub.docker.com/u/ubuntu>prebuilt & preconfigured container image</a> for NGINX.</p><p>When you’re ready to deploy deep learning inference in production, binary size and memory footprint are key considerations – especially when deploying at <a href=http://ubuntu.com/edge-computing>the edge</a>. OpenVINO provides a lightweight Inference Engine with a binary size <a href=https://www.intel.com/content/www/us/en/artificial-intelligence/posts/openvino-reduce-app-footprint.html>of just over 40MB</a> for CPU-based inference. It also provides a Model Server for serving models at scale and managing deployments.</p><p>OpenVINO includes open-source developer tools to improve model inference performance. The first step is to convert a deep learning model (trained with TensorFlow, PyTorch,…) to an Intermediate Representation (IR) using the Model Optimizer. In fact, it cuts the model’s memory usage <a href=https://www.intel.com/content/www/us/en/developer/articles/technical/should-i-choose-fp16-or-fp32-for-my-deep-learning-model.html>in half</a> by converting it from FP32 to FP16 precision.</p><p>Open Model Zoo provides pre-trained models that work for real-world use cases to get you started quickly. Additionally, Python and C++ sample codes demonstrate how to interact with the model. More than 280 pre-trained models are available to download, from speech recognition to natural language processing and computer vision.</p><p>For this blog, we will use the pre-trained colorization models from Open Model Zoo and serve them with Model Server.</p><h2 id=demo-architecture>Demo architecture<a hidden class=anchor aria-hidden=true href=#demo-architecture>#</a></h2><p><strong>“As a user, I can drag and drop my old black and white pictures to my browser so that it displays their ready-to-download colorized version.” – said the PM (me).</strong></p><p>For that – replied the one-time software engineer (still me) – we only need:</p><ul><li>A fancy yet lightweight frontend component.</li><li>OpenVINO™ Model Server to serve the neural network colorization predictions.</li><li>A very light backend component.</li></ul><p><img loading=lazy src=./architecture-diagram-for-demo-app.jpg alt="Architecture diagram colorizer demo app microk8s"></p><p>Whilst we could target the Model Server directly with the frontend (it exposes a REST API), we need to apply transformations to the submitted image. The colorization models, in fact, each expect a specific input.</p><p>Finally, we’ll deploy these three services with Kubernetes because … well … because it’s groovy. And if you think otherwise (everyone is allowed to have a flaw or two), you’ll find a fully functional docker-compose.yaml in the source code repository.</p><p>In the upcoming sections, we will first look at each component and then show how to deploy them with Kubernetes using MicroK8s. Don’t worry; the full source code is <a href=https://github.com/valentincanonical/colouriser-demo>freely available</a>, and I’ll link you to the relevant parts.</p><h3 id=grpc-vs-rest-apis>gRPC vs REST APIs<a hidden class=anchor aria-hidden=true href=#grpc-vs-rest-apis>#</a></h3><p>The OpenVINO Model Server provides inference as a service endpoints for serving models in <a href=https://docs.openvino.ai/latest/openvino_docs_MO_DG_IR_and_opsets.html>OpenVINO IR</a> or <a href=https://onnx.ai/>ONNX</a> format. It also offers centralized model management to serve multiple different models or different versions of the same model and model pipelines.</p><p>The server offers two sets of APIs to interface with it: REST and gRPC. Both APIs are compatible with TensorFlow Serving and expose endpoints for prediction, checking model metadata, and monitoring model status. For use cases where low latency and high throughput are needed, you’ll probably want to interact with the model server via the gRPC API. Indeed, it introduces a significantly smaller overhead than REST. (Read <a href=https://grpc.io/about/>more about gRPC</a>.)</p><p>OpenVINO Model Server is distributed as a <a href=https://hub.docker.com/r/openvino/model_server>Docker image</a> with minimal dependencies. For this demo, we will use the Model Server container image deployed to a MicroK8s cluster. This combination of lightweight technologies is suitable for small deployments such as a developer laptop or edge computing devices.</p><h3 id=neural-network--openvino-model-server>Neural network – OpenVINO Model Server<a hidden class=anchor aria-hidden=true href=#neural-network--openvino-model-server>#</a></h3><p>The colorization neural network is <a href=https://github.com/richzhang/colorization>published under</a> the BSD 2-clause License, accessible from the <a href=https://github.com/openvinotoolkit/open_model_zoo>Open Model Zoo</a>. It’s pre-trained, so we don’t <em>need</em> to understand it in order to use it. However, let’s look closer to understand what input it expects. I also strongly encourage you to read the original work from Richard Zhang, Phillip Isola, and Alexei A. Efros. They made the approach super accessible and understandable on <a href=http://richzhang.github.io/colorization/>this website</a> and in the original <a href=https://arxiv.org/abs/1603.08511>paper</a>.</p><p><img loading=lazy src=./neural-network-architecture.jpg alt="Neural network architecture"></p><p>As you can see on the network architecture diagram, the neural network uses an unusual color space: <strong>LAB</strong>. In fact, there are many 3-dimensional spaces to code colors: RGB, HSL, HSV, etc. The LAB format is relevant here as it fully isolates the color information from the lightness information. Therefore, a grayscale image can be coded with only the L (for Lightness) axis. We will thereore only send the L axis to the neural network’s input. It will generate predictions for the colors coded on the two remaining axes: A and B.</p><p>From the architecture diagram, we can also see that the model expects a 256×256 pixels input size. For these reasons, we cannot just send our RGB-coded grayscale picture in its original size to the network. We need to first transform it.</p><p>We compare the results of two different model versions for the demo. Let them be called ‘V1’ (Siggraph) and ‘V2’. The models are served with the same instance of the OpenVINO™ Model Server as two different models. (We could also have done it with two different versions of the same model – read more in <a href=https://github.com/openvinotoolkit/model_server/blob/main/docs/models_repository.md>the documentation</a>.)</p><p>Finally, to build <a href=https://github.com/valentincanonical/colouriser-demo/blob/main/modelserver/Dockerfile>the Docker image</a>, we use the first stage from the Ubuntu-based development kit to download and convert the model. We then rebase on the more lightweight Model Server image.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-Dockerfile data-lang=Dockerfile><span class=line><span class=cl><span class=c># Dockerfile: github.com/valentincanonical/colouriser-demo/blob/main/modelserver/Dockerfile</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>FROM</span><span class=s> openvino/ubuntu20_dev:latest AS omz</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># download and convert the model</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>…<span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=k>FROM</span><span class=s> openvino/model_server:latest</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span><span class=c># copy the model files and configure the Model Server</span><span class=err>
</span></span></span><span class=line><span class=cl><span class=err></span>…<span class=err>
</span></span></span></code></pre></div><h3 id=backend--ubuntu-based-flask-app-python>Backend – Ubuntu-based Flask app (Python)<a hidden class=anchor aria-hidden=true href=#backend--ubuntu-based-flask-app-python>#</a></h3><p>For the backend microservice that interfaces between the user-facing frontend and the Model Server hosting the neural network, we chose to use Python. There are many valuable libraries to manipulate data, including images, specifically for machine learning applications. To provide web serving capabilities, <a href=https://github.com/pallets/flask>Flask</a> is an easy choice.</p><p>The backend takes an HTTP POST request with the to-be-colorized picture. It synchronously returns the colorized result using the neural network predictions. In between – as we’ve just seen – it needs to convert the input to match the model architecture and to prepare the output to show a displayable result.</p><p>Here’s what the <a href=https://github.com/valentincanonical/colouriser-demo/blob/main/backend/colorize.py#L65>transformation pipeline</a> looks like on the input:</p><p><img loading=lazy src=./transformation-pipline-on-input.png alt="Transformation pipline on input"></p><p>And the output looks something like that:</p><p><img loading=lazy src=./transformation-pipline-on-output.png alt="Transformation pipline on output"></p><p>To containerize our Python Flask application, we use the first stage with all the development dependencies to prepare our execution environment. We copy it onto a fresh Ubuntu base image to run it, configuring the model server’s gRPC connection.</p><h3 id=frontend--ubuntu-based-nginx-container-and-svelte-app>Frontend – Ubuntu-based NGINX container and Svelte app<a hidden class=anchor aria-hidden=true href=#frontend--ubuntu-based-nginx-container-and-svelte-app>#</a></h3><p>Finally, I put together a fancy UI for you to try the solution out. It’s an effortless single-page application with a file input field. It can display side-by-side the results from the two different colorization models.</p><p>I used <a href=https://svelte.dev/>Svelte</a> to build the demo as a dynamic frontend. Below each colorization result, there’s even a saturation slider (using a CSS transformation) so that you can emphasize the predicted colors and better compare the before and after.</p><p>To ship this frontend application, we again use a <a href=https://github.com/valentincanonical/colouriser-demo/blob/main/frontend/Dockerfile>Docker image</a>. We first build the application using the Node base image. We then rebase it on top of a preconfigured Ubuntu-based <a href=https://hub.docker.com/r/ubuntu/nginx>NGINX image</a>. A reverse proxy on the frontend side serves as a passthrough to the backend on the <code>/api</code> endpoint to simplify the deployment configuration. We do that directly in an <a href=https://github.com/valentincanonical/colouriser-demo/blob/main/frontend/nginx.conf>NGINX.conf configuration file</a> copied to the NGINX templates directory. The container image is preconfigured to use these template files with environment variables.</p><h2 id=deployment-with-kubernetes>Deployment with Kubernetes<a hidden class=anchor aria-hidden=true href=#deployment-with-kubernetes>#</a></h2><p>I hope you had the time to digitalize some of your old black and white pictures because things are about to get serious(ly colorized).</p><p>We’ll assume you already have a running Kubernetes installation from the next section. If not, I encourage you to <a href=https://ubuntu.com/tutorials/install-a-local-kubernetes-with-microk8s>go through this MicroK8s tutorial</a>.</p><h3 id=build-the-components-docker-images>Build the components’ Docker images<a hidden class=anchor aria-hidden=true href=#build-the-components-docker-images>#</a></h3><p>Every component comes with a Dockerfile to build itself in a standard environment and ship its deployment dependencies (read <a href=https://ubuntu.com/containers/what-are-containers>What are containers</a> for more information). They all create an Ubuntu-based Docker image for a consistent developer experience.</p><p>Before deploying our colorizer app with Kubernetes, we need to build and push the components’ images. They need to be hosted in a registry accessible from our Kubernetes cluster. We will use the <a href=https://microk8s.io/docs/registry-built-in>built-in local registry</a> with MicroK8s. Depending on your network bandwidth, building and pushing the images will take a few minutes or more.</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>git clone https://github.com/valentincanonical/colouriser-demo.git
</span></span><span class=line><span class=cl><span class=nb>cd</span> colouriser-demo
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Backend</span>
</span></span><span class=line><span class=cl>docker build backend -t localhost:32000/backend:latest
</span></span><span class=line><span class=cl>docker push localhost:32000/backend:latest
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Model Server</span>
</span></span><span class=line><span class=cl>docker build modelserver -t localhost:32000/modelserver:latest
</span></span><span class=line><span class=cl>docker push localhost:32000/modelserver:latest
</span></span><span class=line><span class=cl>
</span></span><span class=line><span class=cl><span class=c1># Frontend</span>
</span></span><span class=line><span class=cl>docker build frontend -t localhost:32000/frontend:latest
</span></span><span class=line><span class=cl>docker push localhost:32000/frontend:latest
</span></span></code></pre></div><h3 id=apply-the-kubernetes-configuration-files>Apply the Kubernetes configuration files<a hidden class=anchor aria-hidden=true href=#apply-the-kubernetes-configuration-files>#</a></h3><p>All the components are now ready for deployment. The Kubernetes configuration files are available as deployments and services YAML descriptors in <a href=https://github.com/valentincanonical/colouriser-demo/tree/main/k8s>the ./K8s folder</a> of the demo repository. We can apply them all at once, in one command:</p><div class=highlight><pre tabindex=0 class=chroma><code class=language-sh data-lang=sh><span class=line><span class=cl>kubectl apply -f ./k8s
</span></span></code></pre></div><p>Give it a few minutes. You can watch the app being deployed with <code>watch kubectl status</code>. Of all the services, the frontend one has a specific <code>NodePort</code> configuration to make it publicly accessible by targeting the Node IP address.</p><p><img loading=lazy src=./ubuntu-command-line-kubernetes-configuration-files.jpg alt="Ubuntu command line kubernetes configuration files"></p><p>Once ready, you can access the demo app at <a href=http://localhost:30000/>http://localhost:30000/</a> (or replace <code>localhost</code> with a cluster node IP address if you’re using a remote cluster). Pick an image from your computer, and get it colorized!</p><h2 id=thats-a-wrap>That’s a wrap!<a hidden class=anchor aria-hidden=true href=#thats-a-wrap>#</a></h2><p>All in all, the project was pretty easy considering the task we accomplished. Thanks to Ubuntu containers, building each component’s image with multi-stage builds was a consistent and straightforward experience. And thanks to OpenVINO™ and the Open Model Zoo, serving a pre-trained model with excellent inference performance was a simple task accessible to all developers.</p><p>Cherry on top, you didn’t even have to share your pics over the Internet to get it done!</p><p><img loading=lazy src=./colorized-example-christmas-cat.png alt="Colorized example christmas cat"></p></div><footer class=post-footer><ul class=post-tags><li><a href=https://mindthegapblog.com/tags/tutorials/>tutorials</a></li><li><a href=https://mindthegapblog.com/tags/tech/>tech</a></li><li><a href=https://mindthegapblog.com/tags/ai/>ai</a></li></ul><nav class=paginav><a class=prev href=https://mindthegapblog.com/posts/open-market-series/><span class=title>« Prev</span><br><span>The Open Market series.</span>
</a><a class=next href=https://mindthegapblog.com/posts/wordle-solver-ai-cnn/><span class=title>Next »</span><br><span>Wordle-ing our way: CNN experiment to solve wordle grids.</span></a></nav></footer></article></main><footer class=footer><span>“The best way to predict the future is to invent it.” Alan Kay
</span><span>—
</span><span>©
2023
</span><span>Valentin Viennot</span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>