<!doctype html><html lang=en dir=auto><head><meta charset=utf-8><meta http-equiv=x-ua-compatible content="IE=edge"><meta name=viewport content="width=device-width,initial-scale=1,shrink-to-fit=no"><meta name=robots content="index, follow"><title>Wordle-ing Our Way to Success: A CNN Experiment to Solve Wordle Grids | Mind the gap blog: Insights, ideas, and inspiration for the tech-savvy and curious.</title><meta name=keywords content="tech,wordle,game,ai"><meta name=description content="Are you a fan of Wordle, the addictive word puzzle game? Have you ever wondered what is the best word to play first? In this blog post, I&rsquo;ll explore the use of Convolutional Neural Networks (CNNs) to solve Wordle grids with a success rate of over 80%.
I should clarify that I&rsquo;m not a data scientist – while I have a passion for machine learning and have completed a few courses on the subject, I am not an AI expert."><meta name=author content="Valentin Viennot"><link rel=canonical href=https://mindthegapblog.com/posts/wordle-solver-ai-cnn/><link crossorigin=anonymous href=/assets/css/stylesheet.b183800e2cfbb62c3bce2b2ba56cdb2dd33af76c75cf4550173d5dfebd7c68a6.css integrity="sha256-sYOADiz7tiw7zisrpWzbLdM692x1z0VQFz1d/r18aKY=" rel="preload stylesheet" as=style><link rel=icon href=https://mindthegapblog.com/favicon.png><link rel=icon type=image/png sizes=16x16 href=https://mindthegapblog.com/favicon-16x16.png><link rel=icon type=image/png sizes=32x32 href=https://mindthegapblog.com/favicon-32x32.png><link rel=apple-touch-icon href=https://mindthegapblog.com/favicon.png><link rel=mask-icon href=https://mindthegapblog.com/favicon.png><meta name=theme-color content="#2e2e33"><meta name=msapplication-TileColor content="#2e2e33"><noscript><style>#theme-toggle,.top-link{display:none}</style><style>@media(prefers-color-scheme:dark){:root{--theme:rgb(29, 30, 32);--entry:rgb(46, 46, 51);--primary:rgb(218, 218, 219);--secondary:rgb(155, 156, 157);--tertiary:rgb(65, 66, 68);--content:rgb(196, 196, 197);--hljs-bg:rgb(46, 46, 51);--code-bg:rgb(55, 56, 62);--border:rgb(51, 51, 51)}.list{background:var(--theme)}.list:not(.dark)::-webkit-scrollbar-track{background:0 0}.list:not(.dark)::-webkit-scrollbar-thumb{border-color:var(--theme)}}</style></noscript><meta property="og:title" content="Wordle-ing Our Way to Success: A CNN Experiment to Solve Wordle Grids"><meta property="og:description" content="Are you a fan of Wordle, the addictive word puzzle game? Have you ever wondered what is the best word to play first? In this blog post, I&rsquo;ll explore the use of Convolutional Neural Networks (CNNs) to solve Wordle grids with a success rate of over 80%.
I should clarify that I&rsquo;m not a data scientist – while I have a passion for machine learning and have completed a few courses on the subject, I am not an AI expert."><meta property="og:type" content="article"><meta property="og:url" content="https://mindthegapblog.com/posts/wordle-solver-ai-cnn/"><meta property="og:image" content="https://mindthegapblog.com/mindthegap-tmp-picture.png"><meta property="article:section" content="posts"><meta property="article:published_time" content="2022-12-31T10:00:29+02:00"><meta property="article:modified_time" content="2022-12-31T10:00:29+02:00"><meta name=twitter:card content="summary_large_image"><meta name=twitter:image content="https://mindthegapblog.com/mindthegap-tmp-picture.png"><meta name=twitter:title content="Wordle-ing Our Way to Success: A CNN Experiment to Solve Wordle Grids"><meta name=twitter:description content="Are you a fan of Wordle, the addictive word puzzle game? Have you ever wondered what is the best word to play first? In this blog post, I&rsquo;ll explore the use of Convolutional Neural Networks (CNNs) to solve Wordle grids with a success rate of over 80%.
I should clarify that I&rsquo;m not a data scientist – while I have a passion for machine learning and have completed a few courses on the subject, I am not an AI expert."><script type=application/ld+json>{"@context":"https://schema.org","@type":"BreadcrumbList","itemListElement":[{"@type":"ListItem","position":1,"name":"Posts","item":"https://mindthegapblog.com/posts/"},{"@type":"ListItem","position":2,"name":"Wordle-ing Our Way to Success: A CNN Experiment to Solve Wordle Grids","item":"https://mindthegapblog.com/posts/wordle-solver-ai-cnn/"}]}</script><script type=application/ld+json>{"@context":"https://schema.org","@type":"BlogPosting","headline":"Wordle-ing Our Way to Success: A CNN Experiment to Solve Wordle Grids","name":"Wordle-ing Our Way to Success: A CNN Experiment to Solve Wordle Grids","description":"Are you a fan of Wordle, the addictive word puzzle game? Have you ever wondered what is the best word to play first? In this blog post, I\u0026rsquo;ll explore the use of Convolutional Neural Networks (CNNs) to solve Wordle grids with a success rate of over 80%.\nI should clarify that I\u0026rsquo;m not a data scientist – while I have a passion for machine learning and have completed a few courses on the subject, I am not an AI expert.","keywords":["tech","wordle","game","ai"],"articleBody":"Are you a fan of Wordle, the addictive word puzzle game? Have you ever wondered what is the best word to play first? In this blog post, I’ll explore the use of Convolutional Neural Networks (CNNs) to solve Wordle grids with a success rate of over 80%.\nI should clarify that I’m not a data scientist – while I have a passion for machine learning and have completed a few courses on the subject, I am not an AI expert. My understanding of the topic is limited, and I only decided to use CNNs for this experiment because that’s what I had learned in university. Please keep this in mind as you read through the post.\nWhat is the best word to play first in Wordle? As the game gained popularity a year ago, my partner and I found ourselves playing regularly. At some point, I noticed that we were both always starting our grids using the same first word every day. He was using “Reals” and I was using “Power”. To be fair I didn’t really think about it, just some kind of habit. But I realised he had better stats than me, maybe thanks to his choice.\nThere surely is a right, scientific answer to the question of what is the best word to play first in Wordle. One approach to finding this word could be to conduct a statistical analysis of the English language, considering factors such as the most common letters and their likelihood of appearing at certain positions in a 5-letter word. Boooooring.\nI remembered my Machine Learning classes and I thought that another, much more fun, way to go about it could be to teach a computer how to play Wordle, and observe. Maybe we could discover the secret to finding the best word to play first. There we go.\nProgramming Wordle for Machine Learning Computer programming is all about inputs and outputs (and one could argue that in an ideal world one would only use functional programming, but that will be another blog). What arguments do we pass to a function, and what results do we expect to see?\nFor our Wordle experiment, the output is clear: the daily Wordle word. But what about the input?\nModelising the game: mental model Note: There are many ways to approach this problem. My approach was influenced by my own experience playing the game and my understanding of CNNs. CNNs are particularly good at manipulating images, and my way to visualise the ongoing Wordle grid state in Wordle was a kind of image in my mind.\nOn The New York Times user interface, the input is a keyboard with some kind of state. It shows letters you can use, words you already tried, and for each letter if it was (1) not in the word, (2) in the word but wrongly placed, (3) in the word and rightfully placed. It also validates what words you’re allowed to play.\nTherefore, one way to represent this game state is as a matrix, with each position and letter representing the information we’ve learned about the word to be found. The matrix would have a 5x26 shape, on one axis the letter position (0-4) and on another axis the letter “code” (0-25). The value would tell us if the letter is (-2) not here for sure, (0) maybe here or nowhere, (1) somewhere in the word, or (2) here for sure.\nThis matrix is what I will adress as the “game state” in the following sections.\nFor each word we try, we can update the game state with the obtained information:\nGREEN: This letter is here (2), therefore no other letter can be here (-2). YELLOW: This letter might is somewhere (1), but we know for sure it’s not here (-2). NONE: This letter is nowhere in the word (-2). Using this mental model, we can code the logic of the game in Python. The “Wordle helper functions” and “Dataset generation” in the accompanying notebook contain all the necessary source code and steps for training a computer to play Wordle.\nNow that we have a way to represent the game state and a plan for programming the logic of the game, we can move on to building a Convolutional Neural Network (CNN) to solve Wordle grids.\nConvolutional Neural Networks: The Wordle Whisperers A Convolutional Neural Network (CNN) is a type of artificial neural network specifically designed for image recognition tasks. It is made up of layers of interconnected nodes, where each node represents a unit of computation. CNN classifiers, which is what we are going to build here, taking a matrice of pixels as input (the image), have multiple hidden computation layers, and an output layer that is a 1D-array of the possible classes.\nIn the context of our Wordle experiment, we can think of each game state as an image, with the position and letter representing different pixels. By training a CNN on a large dataset of game states and their corresponding correct words, we can teach the model to recognize patterns in the game states and make predictions about the correct word to play.\nCNNs are particularly useful for our Wordle task as they are able to capture spatial relationships between pixels in an image. They not only consider one pixel but also its surroundings. In our case, not only one letter and its probabilities to be at this position, but also the surrounding letters and probabilities. This means that CNNs can learn to recognize patterns and features within the game states that might not be immediately apparent to a human observer.\nGenerating the dataset Before we can train our CNN to solve Wordle games, we need to have a dataset of possible game states and their corresponding correct words. In order to generate this dataset, we can use a simple player algorithm that iteratively plays random words from a dictionary, regardless of the game state. By saving the game state and the correct word for each iteration, we can build a large dataset of game states and their corresponding correct words.\nTo generate our dataset, we used a Wordle word list published on GitHub. This list contains 14855 words, therefore a random player has a 1/14855 probability of guessing the correct word on each turn. Given that the player can’t reuse a word, the probability of guessing the correct word on each subsequent turn decreases even further. But it’s so low anyway that we can consider it a binomial distribution (X∼Bin(n,p)) with a success probability of about 0.0001.\nUsing the cumulative binomial probabilities, we find that a random player has a chance of success (P(X\u003e=1, n=6)) of about 0.06%. One game out of 1,600. By playing a large number of games, we can generate a dataset with a good balance of correct and incorrect guesses.\nIn order to generate a human-quality dataset, we only saved a progressed game state and the correct word for each game (LOOP_TRAINING, MATURE_TRAINING). This is because the initial random game state contains no information (only zeros) and would introduce only noise into our dataset.\nWe iterated on over 3.7 million random games, resulting in about 370,000 correct guesses.\nGenerating this random training data can take a significant amount of time. In the linked Google Colab notebook, I have saved the output of the cells so that you can look at the code without having to run the dataset generation yourself (took me about 25mn to generate all the data).\nCrafting the model Now that we have our dataset, it’s time to build the CNN model that will be used to solve Wordle games. In order to do this, we need to consider the shape of our input data (the game state) and the shape of our desired output (the correct word).\nThe input to our model is a matrix with 5 rows (corresponding to the 5 letters in the Wordle game) and 26 columns (corresponding to the 26 letters in the alphabet). The output of our model is a vector with 14855 elements, representing the “probabilities” of each word in our dictionary being the correct answer.\nOur CNN model will have the following architecture:\nThe CNN architecture for solving Wordle consists of a simple 5x26 game input state as the first layer, followed by a 2D convolution layer which allows neighboring elements to influence each other. This helps the CNN to learn what game states “look like” a word or another one, similar to how humans can recognize whether a sequence of letters looks like a probable English word. The output of the convolution layer is then flattened and passed through dense layers to reduce its size and extract relevant information for classification. Finally, the model diverges to a 14855-element array representing the possible words.\nTraining and evaluating the model Now that we’ve crafted our CNN model, it’s time to train it using the previously generated dataset. We’ll use Google Colab for this process and iterate over 15 epochs.\nWhile and after training the model, we’ll need to be able to measure how well it performs in the real Wordle. To evaluate the performance of our model, we will use two metrics:\nAccuracy: This is a common metric for evaluating machine learning models. It represents the rate of correct output guesses given a test input. However, it’s important to note that the accuracy of our model does not necessarily reflect its success at playing Wordle. This is because the input states used to calculate accuracy are already progressed (i.e., they are not completely random like when you start a Wordle game).\nWinning rate: To get a more accurate picture of our model’s performance, we will also calculate the “winning rate” of our model. To do this, we will simulate a large number of Wordle games (using a 6-try, cumulative game state feedback loop) and compute the rate of won games over the total number of played games.\nFor comparison, a completely random player has a winning rate of about 0.06% (calculated using cumulative binomial probabilities, P(X≥1, n=6)). For a more challenging and exciting benchmark, according to the New York Times, my personal winning rate is 96%.\nWordle Victory: CNNs Conquer the Game I put our CNN model to the test and the results were not quite bad! After just 15 minutes of training on a GPU runtime, the model was ready to take on the Wordle. Here’s what happened:\nGenerating the necessary data for training and testing took me 25 minutes The actual training process took just 15 minutes, with 15 epochs on a GPU! Model’s accuracy was a shy 79% – not so bad for a quick machine learning model! I put the model to the ultimate test by having it play 1000 random Wordle games. The winning rate? A pretty good 82% with just over 4 tries on average. While it may not be able to beat human players just yet, our CNN model is definitely on the right track!\nSo, What is The Best First Word to Play in Wordle? One question remains: what is the best first word to play in Wordle?\nThe first word played by our model is “Rales”. It appears to be accepted by Wordle, and to be an anagram of “Reals”, which was a favorite first move of my partner and seemed to yield higher winning rates. Could it be that the key to Wordle success lies in the word “Rales”? Our CNN model seems to think so.\nBONUS: Quordle? In the last cell of the Colab notebook, I have demoed using the trained CNN to play the Quordle variant of the Wordle game. As if playing Wordle wasn’t challenging enough, in Quordle players must juggle four Wordle games at once.\nOne of the main limitations of CNNs is their inability to consider tradeoffs such as “explore vs exploit” when making decisions. In games like Wordle and Quordle, players often have to weigh the benefits of exploring their options (e.g. playing a word that may not be the correct one but provides more information) against the potential rewards of exploiting their current knowledge (e.g. playing a word that they believe is the correct one).\nThere is a cool article on this topic, using reinforcement learning to play Wordle.\nConclusion This experiment demonstrated the potential of Convolutional Neural Networks (CNNs) for solving Wordle grids and potentially even surpassing human players. By training a CNN model on a dataset of random Wordle games, I was able to achieve a success rate of 82% when tested on 1000 games.\nI hope that this blog post has provided an entertaining and informative look at the world of Wordle and machine learning. Whether you’re a seasoned Wordle pro or a beginner, I hope that these insights will inspire you to think more critically when playing your next grid!\nGoogle Colab Notebook ![[won-grid.png]]\n","wordCount":"2143","inLanguage":"en","datePublished":"2022-12-31T10:00:29+02:00","dateModified":"2022-12-31T10:00:29+02:00","author":{"@type":"Person","name":"Valentin Viennot"},"mainEntityOfPage":{"@type":"WebPage","@id":"https://mindthegapblog.com/posts/wordle-solver-ai-cnn/"},"publisher":{"@type":"Organization","name":"Mind the gap blog: Insights, ideas, and inspiration for the tech-savvy and curious.","logo":{"@type":"ImageObject","url":"https://mindthegapblog.com/favicon.png"}}}</script></head><body id=top><script>localStorage.getItem("pref-theme")==="dark"?document.body.classList.add("dark"):localStorage.getItem("pref-theme")==="light"?document.body.classList.remove("dark"):window.matchMedia("(prefers-color-scheme: dark)").matches&&document.body.classList.add("dark")</script><header class=header><nav class=nav><div class=logo><a href=https://mindthegapblog.com/ accesskey=h title="m ind the ga p (Alt + H)">m ind the ga p</a><div class=logo-switches><button id=theme-toggle accesskey=t title="(Alt + T)"><svg id="moon" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><path d="M21 12.79A9 9 0 1111.21 3 7 7 0 0021 12.79z"/></svg><svg id="sun" xmlns="http://www.w3.org/2000/svg" width="24" height="18" viewBox="0 0 24 24" fill="none" stroke="currentcolor" stroke-width="2" stroke-linecap="round" stroke-linejoin="round"><circle cx="12" cy="12" r="5"/><line x1="12" y1="1" x2="12" y2="3"/><line x1="12" y1="21" x2="12" y2="23"/><line x1="4.22" y1="4.22" x2="5.64" y2="5.64"/><line x1="18.36" y1="18.36" x2="19.78" y2="19.78"/><line x1="1" y1="12" x2="3" y2="12"/><line x1="21" y1="12" x2="23" y2="12"/><line x1="4.22" y1="19.78" x2="5.64" y2="18.36"/><line x1="18.36" y1="5.64" x2="19.78" y2="4.22"/></svg></button></div></div><ul id=menu><li><a href=https://valentin.viennot.me/ title=Portfolio><span>Portfolio</span>&nbsp;<svg fill="none" shape-rendering="geometricPrecision" stroke="currentcolor" stroke-linecap="round" stroke-linejoin="round" stroke-width="2.5" viewBox="0 0 24 24" height="12" width="12"><path d="M18 13v6a2 2 0 01-2 2H5a2 2 0 01-2-2V8a2 2 0 012-2h6"/><path d="M15 3h6v6"/><path d="M10 14 21 3"/></svg></a></li></ul></nav></header><main class=main><article class=post-single><header class=post-header><h1 class=post-title>Wordle-ing Our Way to Success: A CNN Experiment to Solve Wordle Grids</h1><div class=post-meta><span title='2022-12-31 10:00:29 +0200 +0200'>December 31, 2022</span>&nbsp;·&nbsp;11 min&nbsp;·&nbsp;Valentin Viennot&nbsp;|&nbsp;<a href=https://github.com/valentinviennot/mindthegapblog/tree/main/content/posts/wordle-ai/index.md rel="noopener noreferrer" target=_blank>Suggest Changes</a></div></header><div class=post-content><p>Are you a fan of Wordle, the addictive word puzzle game? Have you ever wondered what is the best word to play first? In this blog post, I&rsquo;ll explore the use of Convolutional Neural Networks (CNNs) to solve Wordle grids with a success rate of over 80%.</p><blockquote><p>I should clarify that I&rsquo;m not a data scientist – while I have a passion for machine learning and have completed a few courses on the subject, I am not an AI expert. My understanding of the topic is limited, and I only decided to use CNNs for this experiment because that&rsquo;s what I had learned in university. Please keep this in mind as you read through the post.</p></blockquote><h2 id=what-is-the-best-word-to-play-first-in-wordle>What is the best word to play first in Wordle?<a hidden class=anchor aria-hidden=true href=#what-is-the-best-word-to-play-first-in-wordle>#</a></h2><p>As the game gained popularity a year ago, my partner and I found ourselves playing regularly. At some point, I noticed that we were both always starting our grids using the same first word every day. He was using &ldquo;Reals&rdquo; and I was using &ldquo;Power&rdquo;. To be fair I didn&rsquo;t really think about it, just some kind of habit. But I realised he had better stats than me, maybe thanks to his choice.</p><p>There surely is a right, scientific answer to the question of what is the best word to play first in Wordle. One approach to finding this word could be to conduct a statistical analysis of the English language, considering factors such as the most common letters and their likelihood of appearing at certain positions in a 5-letter word. Boooooring.</p><p>I remembered my Machine Learning classes and I thought that another, much more fun, way to go about it could be to teach a computer how to play Wordle, and observe. Maybe we could discover the secret to finding the best word to play first. There we go.</p><h2 id=programming-wordle-for-machine-learning>Programming Wordle for Machine Learning<a hidden class=anchor aria-hidden=true href=#programming-wordle-for-machine-learning>#</a></h2><p>Computer programming is all about inputs and outputs (and one could argue that in an ideal world one would only use functional programming, but that will be another blog). What arguments do we pass to a function, and what results do we expect to see?</p><p>For our Wordle experiment, the output is clear: the daily Wordle word. But what about the input?</p><p><img loading=lazy src=power-wordle-grid.png alt="Wordle grid with Power word as first unsuccessful try."></p><h3 id=modelising-the-game-mental-model>Modelising the game: mental model<a hidden class=anchor aria-hidden=true href=#modelising-the-game-mental-model>#</a></h3><blockquote><p>Note: There are many ways to approach this problem. My approach was influenced by my own experience playing the game and my understanding of CNNs. CNNs are particularly good at manipulating images, and my way to visualise the ongoing Wordle grid state in Wordle was a kind of image in my mind.</p></blockquote><p>On The New York Times <a href=https://www.nytimes.com/games/wordle/index.html>user interface</a>, the input is a keyboard with some kind of state. It shows letters you can use, words you already tried, and for each letter if it was (1) not in the word, (2) in the word but wrongly placed, (3) in the word and rightfully placed. It also validates what words you’re allowed to play.</p><p>Therefore, one way to represent this game state is as a matrix, with each position and letter representing the information we&rsquo;ve learned about the word to be found. The matrix would have a 5x26 shape, on one axis the letter position (0-4) and on another axis the letter &ldquo;code&rdquo; (0-25). The value would tell us if the letter is (-2) not here for sure, (0) maybe here or nowhere, (1) somewhere in the word, or (2) here for sure.</p><p>This matrix is what I will adress as the &ldquo;game state&rdquo; in the following sections.</p><p>For each word we try, we can update the game state with the obtained information:</p><ul><li>GREEN: This letter is here (2), therefore no other letter can be here (-2).</li><li>YELLOW: This letter might is somewhere (1), but we know for sure it’s not here (-2).</li><li>NONE: This letter is nowhere in the word (-2).</li></ul><p><img loading=lazy src=grid.png alt="Mental model of the Wordle game state."></p><p>Using this mental model, we can code the logic of the game in Python. The &ldquo;Wordle helper functions&rdquo; and &ldquo;Dataset generation&rdquo; in the accompanying <a href="https://colab.research.google.com/drive/1w2sFNPswhem8JZFfDAX7JcFXg77YkWyX?usp=sharing">notebook</a> contain all the necessary source code and steps for training a computer to play Wordle.</p><p>Now that we have a way to represent the game state and a plan for programming the logic of the game, we can move on to building a Convolutional Neural Network (CNN) to solve Wordle grids.</p><h2 id=convolutional-neural-networks-the-wordle-whisperers>Convolutional Neural Networks: The Wordle Whisperers<a hidden class=anchor aria-hidden=true href=#convolutional-neural-networks-the-wordle-whisperers>#</a></h2><p>A Convolutional Neural Network (CNN) is a type of artificial neural network specifically designed for image recognition tasks. It is made up of layers of interconnected nodes, where each node represents a unit of computation. CNN classifiers, which is what we are going to build here, taking a matrice of pixels as input (the image), have multiple hidden computation layers, and an output layer that is a 1D-array of the possible classes.</p><p>In the context of our Wordle experiment, we can think of each game state as an image, with the position and letter representing different pixels. By training a CNN on a large dataset of game states and their corresponding correct words, we can teach the model to recognize patterns in the game states and make predictions about the correct word to play.</p><p>CNNs are particularly useful for our Wordle task as they are able to capture spatial relationships between pixels in an image. They not only consider one pixel but also its surroundings. In our case, not only one letter and its probabilities to be at this position, but also the surrounding letters and probabilities. This means that CNNs can learn to recognize patterns and features within the game states that might not be immediately apparent to a human observer.</p><h3 id=generating-the-dataset>Generating the dataset<a hidden class=anchor aria-hidden=true href=#generating-the-dataset>#</a></h3><p>Before we can train our CNN to solve Wordle games, we need to have a dataset of possible game states and their corresponding correct words. In order to generate this dataset, we can use a simple player algorithm that iteratively plays random words from a dictionary, regardless of the game state. By saving the game state and the correct word for each iteration, we can build a large dataset of game states and their corresponding correct words.</p><p>To generate our dataset, we used a Wordle word list published <a href=https://github.com/tabatkins/wordle-list>on GitHub</a>. This list contains 14855 words, therefore a random player has a 1/14855 probability of guessing the correct word on each turn. Given that the player can&rsquo;t reuse a word, the probability of guessing the correct word on each subsequent turn decreases even further. But it&rsquo;s so low anyway that we can consider it a binomial distribution (X∼Bin(n,p)) with a success probability of about 0.0001.</p><p>Using the cumulative binomial probabilities, we find that a random player has a chance of success (P(X>=1, n=6)) of about 0.06%. One game out of 1,600. By playing a large number of games, we can generate a dataset with a good balance of correct and incorrect guesses.</p><p><img loading=lazy src=random-distribution.png alt="Game win rate distribution: human vs random."></p><p>In order to generate a human-quality dataset, we only saved a progressed game state and the correct word for each game (LOOP_TRAINING, MATURE_TRAINING). This is because the initial random game state contains no information (only zeros) and would introduce only noise into our dataset.</p><p>We iterated on over 3.7 million random games, resulting in about 370,000 correct guesses.</p><p>Generating this random training data can take a significant amount of time. In the linked Google <a href="https://colab.research.google.com/drive/1w2sFNPswhem8JZFfDAX7JcFXg77YkWyX?usp=sharing">Colab notebook</a>, I have saved the output of the cells so that you can look at the code without having to run the dataset generation yourself (took me about 25mn to generate all the data).</p><h3 id=crafting-the-model>Crafting the model<a hidden class=anchor aria-hidden=true href=#crafting-the-model>#</a></h3><p>Now that we have our dataset, it&rsquo;s time to build the CNN model that will be used to solve Wordle games. In order to do this, we need to consider the shape of our input data (the game state) and the shape of our desired output (the correct word).</p><p>The input to our model is a matrix with 5 rows (corresponding to the 5 letters in the Wordle game) and 26 columns (corresponding to the 26 letters in the alphabet). The output of our model is a vector with 14855 elements, representing the &ldquo;probabilities&rdquo; of each word in our dictionary being the correct answer.</p><p>Our CNN model will have the following architecture:</p><p><img loading=lazy src=cnn-architecture.png alt="CNN model architecture diagram."></p><p>The CNN architecture for solving Wordle consists of a simple 5x26 game input state as the first layer, followed by a 2D convolution layer which allows neighboring elements to influence each other. This helps the CNN to learn what game states &ldquo;look like&rdquo; a word or another one, similar to how humans can recognize whether a sequence of letters looks like a probable English word. The output of the convolution layer is then flattened and passed through dense layers to reduce its size and extract relevant information for classification. Finally, the model diverges to a 14855-element array representing the possible words.</p><h3 id=training-and-evaluating-the-model>Training and evaluating the model<a hidden class=anchor aria-hidden=true href=#training-and-evaluating-the-model>#</a></h3><p>Now that we&rsquo;ve crafted our CNN model, it&rsquo;s time to train it using the previously generated dataset. We&rsquo;ll use Google Colab for this process and iterate over 15 epochs.</p><p>While and after training the model, we&rsquo;ll need to be able to measure how well it performs in the real Wordle. To evaluate the performance of our model, we will use two metrics:</p><ul><li><p><strong>Accuracy</strong>: This is a common metric for evaluating machine learning models. It represents the rate of correct output guesses given a test input. However, it&rsquo;s important to note that the accuracy of our model does not necessarily reflect its success at playing Wordle. This is because the input states used to calculate accuracy are already progressed (i.e., they are not completely random like when you start a Wordle game).</p></li><li><p><strong>Winning rate</strong>: To get a more accurate picture of our model&rsquo;s performance, we will also calculate the &ldquo;winning rate&rdquo; of our model. To do this, we will simulate a large number of Wordle games (using a 6-try, cumulative game state feedback loop) and compute the rate of won games over the total number of played games.</p></li></ul><p>For comparison, a completely random player has a winning rate of about 0.06% (calculated using cumulative binomial probabilities, P(X≥1, n=6)). For a more challenging and exciting benchmark, according to the New York Times, my personal winning rate is 96%.</p><h2 id=wordle-victory-cnns-conquer-the-game>Wordle Victory: CNNs Conquer the Game<a hidden class=anchor aria-hidden=true href=#wordle-victory-cnns-conquer-the-game>#</a></h2><p>I put our CNN model to the test and the results were not quite bad! After just 15 minutes of training on a GPU runtime, the model was ready to take on the Wordle. Here&rsquo;s what happened:</p><ul><li>Generating the necessary data for training and testing took me 25 minutes</li><li>The actual training process took just 15 minutes, with 15 epochs on a GPU!</li><li>Model&rsquo;s accuracy was a shy 79% – not so bad for a quick machine learning model!</li><li>I put the model to the ultimate test by having it play 1000 random Wordle games. The winning rate? A pretty good 82% with just over 4 tries on average.</li></ul><p>While it may not be able to beat human players just yet, our CNN model is definitely on the right track!</p><h3 id=so-what-is-the-best-first-word-to-play-in-wordle>So, What is The Best First Word to Play in Wordle?<a hidden class=anchor aria-hidden=true href=#so-what-is-the-best-first-word-to-play-in-wordle>#</a></h3><p>One question remains: what is the best first word to play in Wordle?</p><p><img loading=lazy src=rales-wordle.png alt="Wordle grid with first word played is Rales."></p><p>The first word played by our model is &ldquo;Rales&rdquo;. It appears to be accepted by Wordle, and to be an anagram of &ldquo;Reals&rdquo;, which was a favorite first move of my partner and seemed to yield higher winning rates. Could it be that the key to Wordle success lies in the word &ldquo;Rales&rdquo;? Our CNN model seems to think so.</p><h3 id=bonus-quordle>BONUS: Quordle?<a hidden class=anchor aria-hidden=true href=#bonus-quordle>#</a></h3><p>In the last cell of the Colab <a href="https://colab.research.google.com/drive/1w2sFNPswhem8JZFfDAX7JcFXg77YkWyX?usp=sharing">notebook</a>, I have demoed using the trained CNN to play the <a href=https://www.quordle.com/#/>Quordle</a> variant of the Wordle game. As if playing Wordle wasn&rsquo;t challenging enough, in Quordle players must juggle four Wordle games at once.</p><p>One of the main limitations of CNNs is their inability to consider tradeoffs such as &ldquo;explore vs exploit&rdquo; when making decisions. In games like Wordle and Quordle, players often have to weigh the benefits of exploring their options (e.g. playing a word that may not be the correct one but provides more information) against the potential rewards of exploiting their current knowledge (e.g. playing a word that they believe is the correct one).</p><p>There is a cool article on this topic, <a href=https://wandb.ai/andrewkho/wordle-solver/reports/Solving-Wordle-with-Reinforcement-Learning--VmlldzoxNTUzOTc4>using reinforcement learning to play Wordle</a>.</p><h2 id=conclusion>Conclusion<a hidden class=anchor aria-hidden=true href=#conclusion>#</a></h2><p>This experiment demonstrated the potential of Convolutional Neural Networks (CNNs) for solving Wordle grids and potentially even surpassing human players. By training a CNN model on a dataset of random Wordle games, I was able to achieve a success rate of 82% when tested on 1000 games.</p><p>I hope that this blog post has provided an entertaining and informative look at the world of Wordle and machine learning. Whether you&rsquo;re a seasoned Wordle pro or a beginner, I hope that these insights will inspire you to think more critically when playing your next grid!</p><ul><li><a href="https://colab.research.google.com/drive/1w2sFNPswhem8JZFfDAX7JcFXg77YkWyX?usp=sharing">Google Colab Notebook</a></li></ul><p>![[won-grid.png]]</p></div><footer class=post-footer><ul class=post-tags></ul><nav class=paginav><a class=next href=https://mindthegapblog.com/posts/welcome-mindthegap-blog/><span class=title>Next »</span><br><span>Welcome to the mind the gap blog!</span></a></nav></footer></article></main><footer class=footer><span>“The best way to predict the future is to invent it.” Alan Kay</span>
<span>—</span>
<span>©
2022</span>
<span>Valentin Viennot</span></footer><a href=#top aria-label="go to top" title="Go to Top (Alt + G)" class=top-link id=top-link accesskey=g><svg xmlns="http://www.w3.org/2000/svg" viewBox="0 0 12 6" fill="currentcolor"><path d="M12 6H0l6-6z"/></svg></a><script>let menu=document.getElementById("menu");menu&&(menu.scrollLeft=localStorage.getItem("menu-scroll-position"),menu.onscroll=function(){localStorage.setItem("menu-scroll-position",menu.scrollLeft)}),document.querySelectorAll('a[href^="#"]').forEach(e=>{e.addEventListener("click",function(e){e.preventDefault();var t=this.getAttribute("href").substr(1);window.matchMedia("(prefers-reduced-motion: reduce)").matches?document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView():document.querySelector(`[id='${decodeURIComponent(t)}']`).scrollIntoView({behavior:"smooth"}),t==="top"?history.replaceState(null,null," "):history.pushState(null,null,`#${t}`)})})</script><script>var mybutton=document.getElementById("top-link");window.onscroll=function(){document.body.scrollTop>800||document.documentElement.scrollTop>800?(mybutton.style.visibility="visible",mybutton.style.opacity="1"):(mybutton.style.visibility="hidden",mybutton.style.opacity="0")}</script><script>document.getElementById("theme-toggle").addEventListener("click",()=>{document.body.className.includes("dark")?(document.body.classList.remove("dark"),localStorage.setItem("pref-theme","light")):(document.body.classList.add("dark"),localStorage.setItem("pref-theme","dark"))})</script><script>document.querySelectorAll("pre > code").forEach(e=>{const n=e.parentNode.parentNode,t=document.createElement("button");t.classList.add("copy-code"),t.innerHTML="copy";function s(){t.innerHTML="copied!",setTimeout(()=>{t.innerHTML="copy"},2e3)}t.addEventListener("click",t=>{if("clipboard"in navigator){navigator.clipboard.writeText(e.textContent),s();return}const n=document.createRange();n.selectNodeContents(e);const o=window.getSelection();o.removeAllRanges(),o.addRange(n);try{document.execCommand("copy"),s()}catch{}o.removeRange(n)}),n.classList.contains("highlight")?n.appendChild(t):n.parentNode.firstChild==n||(e.parentNode.parentNode.parentNode.parentNode.parentNode.nodeName=="TABLE"?e.parentNode.parentNode.parentNode.parentNode.parentNode.appendChild(t):e.parentNode.appendChild(t))})</script></body></html>