[{"content":" Leaving this here for posterity: \u0026ldquo;Dying isn\u0026rsquo;t as sad as Not living.\u0026rdquo; —Valentin Viennot, 2023\nI know; death is a sad and probably not the most exciting topic for a post. But you needed to read it. In fact, this post is more about life than death. It\u0026rsquo;s more of a wake-up call, an invitation even.\nI\u0026rsquo;m a firm believer that our life choices are investments that shape the value and meaning we extract from life itself. Yes, we\u0026rsquo;re all going to die; get over it. But surely, you don\u0026rsquo;t want to leave this world with a life unlived. There\u0026rsquo;s no perfect time to start investing it wisely and bravely.\nAlso, remember it\u0026rsquo;s all about what you aim to achieve. Some equate \u0026ldquo;living life fully\u0026rdquo; with experiencing intense physical sensations. Some find fulfilment in helping others or creating something new. What\u0026rsquo;s undeniable is that a life lived fully requires taking risks. Why? Because ambitious investment inherently involves risk.\nWhat\u0026rsquo;s your mission?\nIt might sound like a pretty naive question—after all, our existence is quite random. But hold that thought. Now that you\u0026rsquo;re part of a somewhat orderly society, free from the primal instinct of survival, how do you plan to spend your time?\nWe are all born billionaires: Time billionaires. About 2.5 billion seconds. And somehow, I believe we each have a mission. Something meaningful we yearn to accomplish with that time.\nFor me, I distilled my mission into the following statement: \u0026ldquo;To increase human intelligence, both individual and collective, while ensuring my happiness and those of others around me.\u0026rdquo;\nAs documented by Viktor E. Frankl, our primary motivation for living is our will to find meaning in life. Ultimately, an individual\u0026rsquo;s specific mission or purpose in life is unique to them; and discovering it can happen differently. Through great work or encountering someone. As Frankl put it, \u0026ldquo;Ultimately, man should not ask what the meaning of his life is, but rather must recognise that it is he who is asked.\u0026rdquo; That\u0026rsquo;s what keeps us going.\nYou might be thinking, \u0026ldquo;Well, I can\u0026rsquo;t just backpack around the world or quit my job to write a novel. I\u0026rsquo;ve got responsibilities!\u0026rdquo;. And I get that. We all do. But remember, it doesn\u0026rsquo;t require big changes. Helping your child with their homework or even just taking a moment to breathe —that\u0026rsquo;s living, assuming you put meaning into it.\nSo, are you living? Why are you doing this thing you\u0026rsquo;re doing? Or rather, why aren\u0026rsquo;t you doing what you\u0026rsquo;re not doing but wish you were?\nLet’s live. It\u0026rsquo;s your time.\n","permalink":"https://mindthegapblog.com/posts/we-all-have-a-mission/","summary":"Leaving this here for posterity: \u0026ldquo;Dying isn\u0026rsquo;t as sad as Not living.\u0026rdquo; —Valentin Viennot, 2023\nI know; death is a sad and probably not the most exciting topic for a post. But you needed to read it. In fact, this post is more about life than death. It\u0026rsquo;s more of a wake-up call, an invitation even.\nI\u0026rsquo;m a firm believer that our life choices are investments that shape the value and meaning we extract from life itself.","title":"Dying isn't as sad as Not living."},{"content":"All we are doing is investment. Taking the bus to meet a friend? That\u0026rsquo;s an investment. Quitting your job to work at another company? That\u0026rsquo;s investing. Skipping the gym? Bad investment, but still one. Going to bed early? Probably a good investment. So let me give you my best investment advice: spend your time wisely. Imagine you are a millionaire and you are placing your entire fortune into 24 chunks of money every day.\nFrom the online Cambridge dictionary, we get the following definition: \u0026ldquo;Invest, verb. To put money, effort, time, etc. into something to make a profit or get an advantage.\u0026rdquo;\nThinking about this, I mostly consider three investment currencies: Time, Money, and Influence. There surely is more that you can invest into something, but simplistically my opinion is there should be a way to express it as a function of Time, Money, and Influence.\nYou may be thinking this is all wrong, that not everything you do is motivated by \u0026ldquo;making a profit or getting an advantage.\u0026rdquo; And I want to argue you\u0026rsquo;re looking at this the wrong way. Profit is not a bad thing, and doesn\u0026rsquo;t have to be money nor an immediate advantage. In fact, I don\u0026rsquo;t think I\u0026rsquo;m writing anything controversial here: your future is influenced by your many decisions. If you expand the perspectives of what is it that you consider an \u0026ldquo;investment\u0026rdquo; and what is it that you consider a \u0026ldquo;profit\u0026rdquo;, investment goes way beyond money and finance schemes.\nThat\u0026rsquo;s my point. Let me entertain.\nLimiting our view of what investment is to the joys of finance, or at least not seeing our time and influence as equal investment modes, we restrict our ability to have an impact. We are made to believe we need to work in order to get money in order to — if we have some left — invest some. More than a belief, this is indeed what \u0026ldquo;pays the bill\u0026rdquo;. But what if instead of receiving money as a salary you got paid in stocks? That\u0026rsquo;s what some companies do as \u0026ldquo;an incentive\u0026rdquo;. But shouldn\u0026rsquo;t it be the norm? And what if instead of buying your groceries in dollar bills you were trading stocks?\nMoney is convenient. But money is just a transactable token. Without momentum, inert money is worth nothing. Money should always be a mean, never an end.\nTime is a particularly interesting one. Environmental factors aside, Time is the ultimate non-renewable investment resource. Once spent, it\u0026rsquo;s gone forever. And if Money and Influence can buy and leverage Time, they can\u0026rsquo;t create it. It\u0026rsquo;s also a rather fair resource, in that each of us get more or less the same amount to spend (not exactly but it doesn\u0026rsquo;t compare — yet — with the discrepancies in Money or Influence distribution.)\nModern, industrialised societies managed to steal us the freedom of investing our time. If you fit the mold, how much time is left for you at the end of the day to invest in things you truly want? There are ways to adopt a minimalist lifestyle, care less about materialism and money, become as independent as possible from industrialised supply chains\u0026hellip; but this is still quite marginal.\nTrue accomplishment is the freedom to choose where to invest your time.\n(This post is part of the \u0026ldquo;Open Market\u0026rdquo; series)\n","permalink":"https://mindthegapblog.com/posts/all-we-do-is-investment/","summary":"All we are doing is investment. Taking the bus to meet a friend? That\u0026rsquo;s an investment. Quitting your job to work at another company? That\u0026rsquo;s investing. Skipping the gym? Bad investment, but still one. Going to bed early? Probably a good investment. So let me give you my best investment advice: spend your time wisely. Imagine you are a millionaire and you are placing your entire fortune into 24 chunks of money every day.","title":"All we do is invest."},{"content":"Welcome to the playground of my thoughts, a maze of ideas that\u0026rsquo;s been simmering in my mind, only now finding their way to the surface, and to you. This upcoming series of posts truly fits with the vision of the Mind the gap blog. We\u0026rsquo;ll be diving into a topic close to my heart, a complex puzzle made up of many pieces and deep reflections I\u0026rsquo;ve been nurturing for a while.\nThere is an issue with the modern society\u0026rsquo;s approach to Work and how it values —or, in my view, fails to appreciate— individual contributions adequately. This topic finds interesting parallels with recent debates and demonstrations over retirement policies in France —the country I love and live in.\nMy stance on this matter isn\u0026rsquo;t easily distilled into a single sentence, but if I were to attempt it, I\u0026rsquo;d say I envision a world where everyone can earn a living from their craft and contribute solely to causes they passionately believe in. Realizing this vision calls for a significant societal shift —a form of \u0026lsquo;de-alienation\u0026rsquo;— where people feel a real connection to the results of their work, possibly fostered through communities collaborating on projects.\nIn this context, I\u0026rsquo;ve been thinking of a market that shifts its focus from pure profit to societal benefit as a method to assess these projects\u0026rsquo; value. This concept does not imply a specific governance model for individual projects or society overall. This \u0026lsquo;open market\u0026rsquo;—a concept I\u0026rsquo;ll elaborate on in future posts— could support democratic governance, steering individual contributions towards successful (or in other words, beneficial to society) products and services.\nOpen Source communities and projects provide encouraging examples of what this world could look like. Unfortunately, a sustainable business model to back these communities is yet to be found. As it stands, Open Source struggles to flourish beyond the umbrella of large corporations and their strategic open-sourced code repositories. I actually genuinely worry that free, libre, software (\u0026ldquo;Open Source\u0026rdquo;) might stand at the precipice of extinction.\nMy dream? Finding a systemic way to financially support an Open Source world —an open platform to sustainably invest in free software. Meanwhile, I\u0026rsquo;ll be writing a series of posts related to this subject, in the hopes of sparking stimulating discussions. Feel free to challenge me: I\u0026rsquo;m on Twitter!.\nUpcoming posts of this Open Market series will fall in mostly four categories:\nMeans of Production Markets Value Work Looking forward to posting more and reading your thoughts.\n\u0026hellip; WORK IN PROGRESS \u0026hellip;\nAll we do is invest: Money, Time, Influence. ","permalink":"https://mindthegapblog.com/posts/open-market-series/","summary":"Welcome to the playground of my thoughts, a maze of ideas that\u0026rsquo;s been simmering in my mind, only now finding their way to the surface, and to you. This upcoming series of posts truly fits with the vision of the Mind the gap blog. We\u0026rsquo;ll be diving into a topic close to my heart, a complex puzzle made up of many pieces and deep reflections I\u0026rsquo;ve been nurturing for a while.","title":"The Open Market series."},{"content":"If you’re looking to bring a stack of old family photos back to life, check out Ubuntu’s demo on how to use OpenVINO on Ubuntu containers to colorize monochrome pictures. This magical use of containers, neural networks, and Kubernetes is packed with helpful resources and a fun way to dive into deep learning!\nA version of Part 1 and Part 2 of this article was first published on Ubuntu’s blog.\nA few words about OpenVINO on Ubuntu containers Docker image security isn’t only about provenance and supply chains; it’s also about the user experience. More specifically, the developer experience.\nAs the most popular container image in its category, the Ubuntu base image provides a seamless, easy-to-set-up experience. From public cloud hosts to IoT devices, the Ubuntu experience is consistent and loved by developers. In this blog, you’ll see that using Ubuntu Docker images greatly simplifies component containerization. We even used a prebuilt \u0026amp; preconfigured container image for NGINX.\nWhen you’re ready to deploy deep learning inference in production, binary size and memory footprint are key considerations – especially when deploying at the edge. OpenVINO provides a lightweight Inference Engine with a binary size of just over 40MB for CPU-based inference. It also provides a Model Server for serving models at scale and managing deployments.\nOpenVINO includes open-source developer tools to improve model inference performance. The first step is to convert a deep learning model (trained with TensorFlow, PyTorch,…) to an Intermediate Representation (IR) using the Model Optimizer. In fact, it cuts the model’s memory usage in half by converting it from FP32 to FP16 precision.\nOpen Model Zoo provides pre-trained models that work for real-world use cases to get you started quickly. Additionally, Python and C++ sample codes demonstrate how to interact with the model. More than 280 pre-trained models are available to download, from speech recognition to natural language processing and computer vision.\nFor this blog, we will use the pre-trained colorization models from Open Model Zoo and serve them with Model Server.\nDemo architecture “As a user, I can drag and drop my old black and white pictures to my browser so that it displays their ready-to-download colorized version.” – said the PM (me).\nFor that – replied the one-time software engineer (still me) – we only need:\nA fancy yet lightweight frontend component. OpenVINO™ Model Server to serve the neural network colorization predictions. A very light backend component. Whilst we could target the Model Server directly with the frontend (it exposes a REST API), we need to apply transformations to the submitted image. The colorization models, in fact, each expect a specific input.\nFinally, we’ll deploy these three services with Kubernetes because … well … because it’s groovy. And if you think otherwise (everyone is allowed to have a flaw or two), you’ll find a fully functional docker-compose.yaml in the source code repository.\nIn the upcoming sections, we will first look at each component and then show how to deploy them with Kubernetes using MicroK8s. Don’t worry; the full source code is freely available, and I’ll link you to the relevant parts.\ngRPC vs REST APIs The OpenVINO Model Server provides inference as a service endpoints for serving models in OpenVINO IR or ONNX format. It also offers centralized model management to serve multiple different models or different versions of the same model and model pipelines.\nThe server offers two sets of APIs to interface with it: REST and gRPC. Both APIs are compatible with TensorFlow Serving and expose endpoints for prediction, checking model metadata, and monitoring model status. For use cases where low latency and high throughput are needed, you’ll probably want to interact with the model server via the gRPC API. Indeed, it introduces a significantly smaller overhead than REST. (Read more about gRPC.)\nOpenVINO Model Server is distributed as a Docker image with minimal dependencies. For this demo, we will use the Model Server container image deployed to a MicroK8s cluster. This combination of lightweight technologies is suitable for small deployments such as a developer laptop or edge computing devices.\nNeural network – OpenVINO Model Server The colorization neural network is published under the BSD 2-clause License, accessible from the Open Model Zoo. It’s pre-trained, so we don’t need to understand it in order to use it. However, let’s look closer to understand what input it expects. I also strongly encourage you to read the original work from Richard Zhang, Phillip Isola, and Alexei A. Efros. They made the approach super accessible and understandable on this website and in the original paper.\nAs you can see on the network architecture diagram, the neural network uses an unusual color space: LAB. In fact, there are many 3-dimensional spaces to code colors: RGB, HSL, HSV, etc. The LAB format is relevant here as it fully isolates the color information from the lightness information. Therefore, a grayscale image can be coded with only the L (for Lightness) axis. We will thereore only send the L axis to the neural network’s input. It will generate predictions for the colors coded on the two remaining axes: A and B.\nFrom the architecture diagram, we can also see that the model expects a 256×256 pixels input size. For these reasons, we cannot just send our RGB-coded grayscale picture in its original size to the network. We need to first transform it.\nWe compare the results of two different model versions for the demo. Let them be called ‘V1’ (Siggraph) and ‘V2’. The models are served with the same instance of the OpenVINO™ Model Server as two different models. (We could also have done it with two different versions of the same model – read more in the documentation.)\nFinally, to build the Docker image, we use the first stage from the Ubuntu-based development kit to download and convert the model. We then rebase on the more lightweight Model Server image.\n# Dockerfile: github.com/valentincanonical/colouriser-demo/blob/main/modelserver/Dockerfile FROM openvino/ubuntu20_dev:latest AS omz # download and convert the model … FROM openvino/model_server:latest # copy the model files and configure the Model Server … Backend – Ubuntu-based Flask app (Python) For the backend microservice that interfaces between the user-facing frontend and the Model Server hosting the neural network, we chose to use Python. There are many valuable libraries to manipulate data, including images, specifically for machine learning applications. To provide web serving capabilities, Flask is an easy choice.\nThe backend takes an HTTP POST request with the to-be-colorized picture. It synchronously returns the colorized result using the neural network predictions. In between – as we’ve just seen – it needs to convert the input to match the model architecture and to prepare the output to show a displayable result.\nHere’s what the transformation pipeline looks like on the input:\nAnd the output looks something like that:\nTo containerize our Python Flask application, we use the first stage with all the development dependencies to prepare our execution environment. We copy it onto a fresh Ubuntu base image to run it, configuring the model server’s gRPC connection.\nFrontend – Ubuntu-based NGINX container and Svelte app Finally, I put together a fancy UI for you to try the solution out. It’s an effortless single-page application with a file input field. It can display side-by-side the results from the two different colorization models.\nI used Svelte to build the demo as a dynamic frontend. Below each colorization result, there’s even a saturation slider (using a CSS transformation) so that you can emphasize the predicted colors and better compare the before and after.\nTo ship this frontend application, we again use a Docker image. We first build the application using the Node base image. We then rebase it on top of a preconfigured Ubuntu-based NGINX image. A reverse proxy on the frontend side serves as a passthrough to the backend on the /api endpoint to simplify the deployment configuration. We do that directly in an NGINX.conf configuration file copied to the NGINX templates directory. The container image is preconfigured to use these template files with environment variables.\nDeployment with Kubernetes I hope you had the time to digitalize some of your old black and white pictures because things are about to get serious(ly colorized).\nWe’ll assume you already have a running Kubernetes installation from the next section. If not, I encourage you to go through this MicroK8s tutorial.\nBuild the components’ Docker images Every component comes with a Dockerfile to build itself in a standard environment and ship its deployment dependencies (read What are containers for more information). They all create an Ubuntu-based Docker image for a consistent developer experience.\nBefore deploying our colorizer app with Kubernetes, we need to build and push the components’ images. They need to be hosted in a registry accessible from our Kubernetes cluster. We will use the built-in local registry with MicroK8s. Depending on your network bandwidth, building and pushing the images will take a few minutes or more.\ngit clone https://github.com/valentincanonical/colouriser-demo.git cd colouriser-demo # Backend docker build backend -t localhost:32000/backend:latest docker push localhost:32000/backend:latest # Model Server docker build modelserver -t localhost:32000/modelserver:latest docker push localhost:32000/modelserver:latest # Frontend docker build frontend -t localhost:32000/frontend:latest docker push localhost:32000/frontend:latest Apply the Kubernetes configuration files All the components are now ready for deployment. The Kubernetes configuration files are available as deployments and services YAML descriptors in the ./K8s folder of the demo repository. We can apply them all at once, in one command:\nkubectl apply -f ./k8s Give it a few minutes. You can watch the app being deployed with watch kubectl status. Of all the services, the frontend one has a specific NodePort configuration to make it publicly accessible by targeting the Node IP address.\nOnce ready, you can access the demo app at http://localhost:30000/ (or replace localhost with a cluster node IP address if you’re using a remote cluster). Pick an image from your computer, and get it colorized!\nThat’s a wrap! All in all, the project was pretty easy considering the task we accomplished. Thanks to Ubuntu containers, building each component’s image with multi-stage builds was a consistent and straightforward experience. And thanks to OpenVINO™ and the Open Model Zoo, serving a pre-trained model with excellent inference performance was a simple task accessible to all developers.\nCherry on top, you didn’t even have to share your pics over the Internet to get it done!\n","permalink":"https://mindthegapblog.com/posts/colorize-black-white-pictures/","summary":"If you’re looking to bring a stack of old family photos back to life, check out Ubuntu’s demo on how to use OpenVINO on Ubuntu containers to colorize monochrome pictures. This magical use of containers, neural networks, and Kubernetes is packed with helpful resources and a fun way to dive into deep learning!\nA version of Part 1 and Part 2 of this article was first published on Ubuntu’s blog.","title":"How to colorize black \u0026 white pictures."},{"content":"Are you a fan of Wordle, the addictive word puzzle game? Have you ever wondered what is the best word to play first? In this blog post, I\u0026rsquo;ll explore the use of Convolutional Neural Networks (CNNs) to solve Wordle grids with a success rate of over 80%.\nI should clarify that I\u0026rsquo;m not a data scientist – while I have a passion for machine learning and have completed a few courses on the subject, I am not an AI expert. My understanding of the topic is limited, and I only decided to use CNNs for this experiment because that\u0026rsquo;s what I had learned in university. Please keep this in mind as you read through the post.\nWhat is the best word to play first in Wordle? As the game gained popularity a year ago, my partner and I found ourselves playing regularly. At some point, I noticed that we were both always starting our grids using the same first word every day. He was using \u0026ldquo;Reals\u0026rdquo; and I was using \u0026ldquo;Power\u0026rdquo;. To be fair I didn\u0026rsquo;t really think about it, just some kind of habit. But I realised he had better stats than me, maybe thanks to his choice.\nThere surely is a right, scientific answer to the question of what is the best word to play first in Wordle. One approach to finding this word could be to conduct a statistical analysis of the English language, considering factors such as the most common letters and their likelihood of appearing at certain positions in a 5-letter word. Boooooring.\nI remembered my Machine Learning classes and I thought that another, much more fun, way to go about it could be to teach a computer how to play Wordle, and observe. Maybe we could discover the secret to finding the best word to play first. There we go.\nProgramming Wordle for Machine Learning Computer programming is all about inputs and outputs (and one could argue that in an ideal world one would only use functional programming, but that will be another blog). What arguments do we pass to a function, and what results do we expect to see?\nFor our Wordle experiment, the output is clear: the daily Wordle word. But what about the input?\nModelising the game: mental model Note: There are many ways to approach this problem. My approach was influenced by my own experience playing the game and my understanding of CNNs. CNNs are particularly good at manipulating images, and my way to visualise the ongoing Wordle grid state in Wordle was a kind of image in my mind.\nOn The New York Times user interface, the input is a keyboard with some kind of state. It shows letters you can use, words you already tried, and for each letter if it was (1) not in the word, (2) in the word but wrongly placed, (3) in the word and rightfully placed. It also validates what words you’re allowed to play.\nTherefore, one way to represent this game state is as a matrix, with each position and letter representing the information we\u0026rsquo;ve learned about the word to be found. The matrix would have a 5x26 shape, on one axis the letter position (0-4) and on another axis the letter \u0026ldquo;code\u0026rdquo; (0-25). The value would tell us if the letter is (-2) not here for sure, (0) maybe here or nowhere, (1) somewhere in the word, or (2) here for sure.\nThis matrix is what I will adress as the \u0026ldquo;game state\u0026rdquo; in the following sections.\nFor each word we try, we can update the game state with the obtained information:\nGREEN: This letter is here (2), therefore no other letter can be here (-2). YELLOW: This letter might is somewhere (1), but we know for sure it’s not here (-2). NONE: This letter is nowhere in the word (-2). Using this mental model, we can code the logic of the game in Python. The \u0026ldquo;Wordle helper functions\u0026rdquo; and \u0026ldquo;Dataset generation\u0026rdquo; in the accompanying notebook contain all the necessary source code and steps for training a computer to play Wordle.\nNow that we have a way to represent the game state and a plan for programming the logic of the game, we can move on to building a Convolutional Neural Network (CNN) to solve Wordle grids.\nConvolutional Neural Networks: The Wordle Whisperers A Convolutional Neural Network (CNN) is a type of artificial neural network specifically designed for image recognition tasks. It is made up of layers of interconnected nodes, where each node represents a unit of computation. CNN classifiers, which is what we are going to build here, take a matrice of pixels as their input (the image), have multiple hidden computation layers, and their output layer is a 1D-array of the possible classes.\nIn the context of our Wordle experiment, we can think of each game state as an image, with the position and letter representing different pixels. By training a CNN on a large dataset of game states and their corresponding correct words, we can teach the model to recognize patterns in the game states and make predictions about the correct word to play.\nCNNs are particularly useful for our Wordle task as they are able to capture spatial relationships between pixels in an image. They not only consider one pixel but also its surroundings. In our case, not only one letter and its probabilities to be at this position, but also the surrounding letters and probabilities. This means that CNNs can learn to recognize patterns and features within the game states that might not be immediately apparent to a human observer.\nGenerating the dataset Before we can train our CNN to solve Wordle games, we need to have a dataset of possible game states and their corresponding correct words. In order to generate this dataset, we can use a simple player algorithm that iteratively plays random words from a dictionary, regardless of the game state. By saving the game state and the correct word for each iteration, we can build a large dataset of game states and their corresponding correct words.\nTo generate our dataset, we used a Wordle word list published on GitHub. This list contains 14855 words, therefore a random player has a 1/14855 probability of guessing the correct word on each turn. Given that the player can\u0026rsquo;t reuse a word, the probability of guessing the correct word on each subsequent turn decreases even further. But it\u0026rsquo;s so low anyway that we can consider it a binomial distribution (X∼Bin(n,p)) with a success probability of about 0.0001.\nUsing the cumulative binomial probabilities, we find that a random player has a chance of success (P(X\u0026gt;=1, n=6)) of about 0.06%. One game out of 1,600. By playing a large number of games, we can generate a dataset with a good balance of correct and incorrect guesses.\nIn order to generate a human-quality dataset, we only saved a progressed game state and the correct word for each game (LOOP_TRAINING, MATURE_TRAINING). This is because the initial random game state contains no information (only zeros) and would introduce only noise into our dataset.\nWe iterated on over 3.7 million random games, resulting in about 370,000 correct guesses.\nGenerating this random training data can take a significant amount of time. In the linked Google Colab notebook, I have saved the output of the cells so that you can look at the code without having to run the dataset generation yourself (took me about 25mn to generate all the data).\nCrafting the model Now that we have our dataset, it\u0026rsquo;s time to build the CNN model that will be used to solve Wordle games. In order to do this, we need to consider the shape of our input data (the game state) and the shape of our desired output (the correct word).\nThe input to our model is a matrix with 5 rows (corresponding to the 5 letters in the Wordle game) and 26 columns (corresponding to the 26 letters in the alphabet). The output of our model is a vector with 14855 elements, representing the \u0026ldquo;probabilities\u0026rdquo; of each word in our dictionary being the correct answer.\nOur CNN model will have the following architecture:\nThe CNN architecture for solving Wordle consists of a simple 5x26 game input state as the first layer, followed by a 2D convolution layer which allows neighboring elements to influence each other. This helps the CNN to learn what game states \u0026ldquo;look like\u0026rdquo; a word or another one, similar to how humans can recognize whether a sequence of letters looks like a probable English word. The output of the convolution layer is then flattened and passed through dense layers to reduce its size and extract relevant information for classification. Finally, the model diverges to a 14855-element array representing the possible words.\nTraining and evaluating the model Now that we\u0026rsquo;ve crafted our CNN model, it\u0026rsquo;s time to train it using the previously generated dataset. We\u0026rsquo;ll use Google Colab for this process and iterate over 15 epochs.\nWhile and after training the model, we\u0026rsquo;ll need to be able to measure how well it performs in the real Wordle. To evaluate the performance of our model, we will use two metrics:\nAccuracy: This is a common metric for evaluating machine learning models. It represents the rate of correct output guesses given a test input. However, it\u0026rsquo;s important to note that the accuracy of our model does not necessarily reflect its success at playing Wordle. This is because the input states used to calculate accuracy are already progressed (i.e., they are not completely random like when you start a Wordle game).\nWinning rate: To get a more accurate picture of our model\u0026rsquo;s performance, we will also calculate the \u0026ldquo;winning rate\u0026rdquo; of our model. To do this, we will simulate a large number of Wordle games (using a 6-try, cumulative game state feedback loop) and compute the rate of won games over the total number of played games.\nFor comparison, a completely random player has a winning rate of about 0.06% (calculated using cumulative binomial probabilities, P(X≥1, n=6)). For a more challenging and exciting benchmark, according to the New York Times, my personal winning rate is 96%.\nWordle Victory: CNNs Conquer the Game I put our CNN model to the test and the results were not quite bad! After just 15 minutes of training on a GPU runtime, the model was ready to take on the Wordle. Here\u0026rsquo;s what happened:\nGenerating the necessary data for training and testing took me 25 minutes The actual training process took just 15 minutes, with 15 epochs on a GPU! Model\u0026rsquo;s accuracy was a shy 79% – not so bad for a quick machine learning model! I put the model to the ultimate test by having it play 1000 random Wordle games. The winning rate? A pretty good 82% with just over 4 tries on average. While it may not be able to beat human players just yet, our CNN model is definitely on the right track!\nSo, What is The Best First Word to Play in Wordle? One question remains: what is the best first word to play in Wordle?\nThe first word played by our model is \u0026ldquo;Rales\u0026rdquo;. It appears to be accepted by Wordle, and to be an anagram of \u0026ldquo;Reals\u0026rdquo;, which was a favorite first move of my partner and seemed to yield higher winning rates. Could it be that the key to Wordle success lies in the word \u0026ldquo;Rales\u0026rdquo;? Our CNN model seems to think so.\nBONUS: Quordle? In the last cell of the Colab notebook, I have demoed using the trained CNN to play the Quordle variant of the Wordle game. As if playing Wordle wasn\u0026rsquo;t challenging enough, in Quordle, players must juggle four Wordle games at once.\nOne of the main limitations of CNNs is their inability to consider tradeoffs such as \u0026ldquo;explore vs exploit\u0026rdquo; when making decisions. In games like Wordle and Quordle, players often have to weigh the benefits of exploring their options (e.g. playing a word that may not be the correct one but provides more information) against the potential rewards of exploiting their current knowledge (e.g. playing a word that they believe is the correct one).\nThere is a cool article on this topic, using reinforcement learning to play Wordle.\nConclusion This experiment demonstrated the potential of Convolutional Neural Networks (CNNs) for solving Wordle grids and potentially even surpassing human players. By training a CNN model on a dataset of random Wordle games, I was able to achieve a success rate of 82% when tested on 1000 games.\nI hope that this blog post has provided an entertaining and informative look at the world of Wordle and machine learning. Whether you\u0026rsquo;re a seasoned Wordle pro or a beginner, I hope that these insights will inspire you to think more critically when playing your next grid!\nGoogle Colab Notebook ","permalink":"https://mindthegapblog.com/posts/wordle-solver-ai-cnn/","summary":"Are you a fan of Wordle, the addictive word puzzle game? Have you ever wondered what is the best word to play first? In this blog post, I\u0026rsquo;ll explore the use of Convolutional Neural Networks (CNNs) to solve Wordle grids with a success rate of over 80%.\nI should clarify that I\u0026rsquo;m not a data scientist – while I have a passion for machine learning and have completed a few courses on the subject, I am not an AI expert.","title":"Wordle-ing our way: CNN experiment to solve wordle grids."},{"content":"Hi everyone!\nI\u0026rsquo;m Valentin, a passionate inventor using technology to make the world a better place. I am on a mission to increase both individual and collective intelligence, and to inspire and challenge you to think critically. This blog will mix thoughts, experiments, and ideas on a various topics, including tech, design, and society.\nI grew up with a natural curiosity and a desire to solve problems with my ideas and inventions. This eventually led me to pursue an engineering degree in Communication Systems and now to work as a Product Manager for the company behind Ubuntu where I\u0026rsquo;m contributing to bringing free software to the widest audience.\nOne of my earliest experiences with the Internet was as a teenager, when I actually didn\u0026rsquo;t have network access at home. Though, I was determined to connect to the Internet. So I tried to remember and reproduce the IP and DNS configuration from the computers at school. No need to say: it did\u0026rsquo;t work!\nLooking back, I\u0026rsquo;m grateful that I didn\u0026rsquo;t have access to this powerful, unlimited resource too early in my life. It gave me the time to be bored. Boredom is essential to build creativity and a critical mind.\nAnyway ; now, here I am writing to the world on the (real) Internet. I truly hope my stories and ideas will inspire some of you.\nFeel free to reach out to me on Twitter (you can find me at @ValentinViennot) or via email (blog@viennot.me) with any feedback or suggestions.\nWishing you a good read, Valentin.\n(DALL-E2 might be good at drawings, but not so much at writing texts.)\n","permalink":"https://mindthegapblog.com/posts/welcome-mindthegap-blog/","summary":"Hi everyone!\nI\u0026rsquo;m Valentin, a passionate inventor using technology to make the world a better place. I am on a mission to increase both individual and collective intelligence, and to inspire and challenge you to think critically. This blog will mix thoughts, experiments, and ideas on a various topics, including tech, design, and society.\nI grew up with a natural curiosity and a desire to solve problems with my ideas and inventions.","title":"Welcome to the mind the gap blog!"}]